---
layout: post
title: TravelApp II - Cold Start Problem
description: Building a Neural Collaborative Auto-Filter
image: assets/images/cover.png
---

Today I'll be continuing my discussion of the TravelApp recommender system. Recall that our goal is to take a bunch of user-generated attraction ratings and then use this to make predictions about which attractions a new user might like.  So, our input data looks like this:


<table>
    <tr>
      <th>Name</th>
      <th>Golden Gate Bridge</th>
      <th>Alcatraz</th>
      <th> Gregangelo </th>
      <th> SF MoMA </th>
    </tr>
    <tr>
      <td>Alice</td>
      <td>5</td>
      <td>4</td>
      <td> <font color="red">?</font> </td>
      <td> 2 </td>
    </tr>
    <tr>
      <td>Bob</td>
      <td>4</td>
      <td><font color="red">?</font></td>
      <td> 0 </td>
      <td> <font color="red">?</font> </td>
    </tr>
    <tr>
      <td>Charlie</td>
      <td>0</td>
      <td>2</td>
      <td> 5</td>
      <td> 4</td>
    </tr>
    <tr>
      <td> Tom </td>
      <td> <font color="red">?</font> </td>
      <td> 2 </td>
      <td> 4 </td>
      <td> 5 </td>
    </tr>
</table>

...and our goal is to figure out where a first-time user of our app would like to visit.  

Now, if our putative new user had *already* rated dozens of attractions then we could just build a collaborative auto-filter, as described in a previous post.  However, we are by assumption interested in a new user who is visiting a new city for the first time.  There probably won't be much overlap between attractions visited by the individual and the ones in a given city.  

So, what should we do?  Clearly, we need to have *some* data on this user in order to get started.  Without anything better, all we can do is ask the user how much they like certain qualities of travel attractions and then try to match them to attractions with similar qualities.  We will call these user-defined features **preferences**.  Since the user will be asked to rate their preference in several categories, we will speak of a **preference vector**.

Now, we also want the power of neural networks so that we can capture non-linearities and keep improving as our information on the user increases.  Thus, our solution is to append the **preference (row) vector** to the row-vector of ratings which we assign to each user.  Of course, for a new user, the ratings will be `NaN`, but then we are back in the situation where we can use the collaborative auto-filter again!  

Pictorially, we have something like this:

<img src="https://drive.google.com/uc?id=1Pmve5AFc_deA79EF-sDPSzIA6fQXH07M" alt="image"/>

Ok, so how do we get **preference vectors** to add to our user data to begin with?  Well, I apologize but we're going to need to make some arbitrary, albeit reasonable, choices in order to move forward.  For the new user, the answer is simple - we make up some categories, "Nature, Culture, History and Recreation" to be specific, and then ask the user to rate themselves on a scale of -10 to 10.  The interface (at this very moment) looks like:

<img src="https://drive.google.com/uc?id=1Ys-UevLFgJukTGfmyn9i1gQjvvKFZ0nl" alt="image"/>

So, this user loves Nature and is ambivalent about Culture, History and Recreation.  (He also wants to travel from 8am to 5pm and has $2000 to blow.)

Next, we need to generate some kind of comparable **preference vector** for the users in our database.  This is where it gets a little bit tricky.  A-priori, we don't know how to correlate the self-rankings of a new user to the profiles we have in our database.  However, since we need to do something, here how we proceed.  First, we note that the travel sites sourcing our data provide tags to describe each site, i.e, things like "Hiking" or "Museum".  We then map all of these tags (several hundred of them) to our categories.  For instance, a "Art Museum" gets translated to "Culture" and "Hiking" gets translated to "Nature".  Thus, an attraction that has the tags "Hiking and Art Museum" will be assigned a preference vector (1,0,1,0) in the (Nature,History,Culture,Recreation) basis. Sometimes it gets tricky.  For instance, a log cabin is purely history, but a history museum could be both "History" and "Culture".  In any case, we will just sum up the various tags translated into our basis to get a feature vector for a site.  For an individual use, we then take a linear combination of all the places they've visited, weighted by the scores they've assigned each attraction.  In pictures, we have:

<img src="https://drive.google.com/uc?id=1-t-w-wAOJ5Qh-QHdNdxzOqSc4L2sMo91" alt="image"/>

As a final step, we convert all of these numbers to percentiles and then scale the result to the range 0 to 10.  Converting to percentiles makes the data much more smooth and so the neural network will train more quickly.  We map to the range 0 to 10 (and not -10 to 10 as with our new-user inputs) because people just don't go to places they don't like.  In other words, even if someone tends to rank Nature places lowly, the fact that they went at all means they don't "hate" nature too much.  On the other hand, some people do truly hate the outdoors and would have never gone in the first place.  Thus, our sliders have an additional range of values that account for people who aren't represented in the dataset because they never visited a certain kind of attraction in the first place.    

One may questions all these assumptions, but, at the very least, we are able to generate a recommender system that is very sensitive to the users input.  I.e., changing the input will change the recommendations in a 'reasonable' way.  Let's see what the output is for the settings above:

<img src="https://drive.google.com/uc?id=17f8rjfg93G0B62Efe6iqTiSH3w9O1QGZ" alt="image"/>

Not so bad, we do indeed get a lot of Nature-heavy recommendations as expected.  The next step is to use these to build an actual itinerary, to be discussed later!
